{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4b45f-044d-4454-8599-4e839e09a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置环境变量以避免多次加载库的问题\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# 定义数据集的基本路径\n",
    "base_dir = 'D:/dataset'\n",
    "\n",
    "# 数据目录\n",
    "data_directory = base_dir\n",
    "\n",
    "# 批处理大小\n",
    "batch_size = 100\n",
    "\n",
    "# 加载训练数据集\n",
    "train_data = dsets.MNIST(\n",
    "    root=data_directory,  # 数据存储的根目录\n",
    "    train=True,  # 加载训练集\n",
    "    transform=None,  # 不使用任何数据转换\n",
    "    download=True  # 如果数据集不存在则下载\n",
    ")\n",
    "\n",
    "# 加载测试数据集\n",
    "test_data = dsets.MNIST(\n",
    "    root=data_directory,\n",
    "    train=False,  # 加载测试集\n",
    "    transform=None,  # 不使用任何数据转换\n",
    "    download=True  # 如果数据集不存在则下载\n",
    ")\n",
    "\n",
    "# 打印确认信息\n",
    "print('helloworld')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b7236-a5dd-49e0-8b5e-6d7bf57c3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置环境变量以避免多次加载库的问题\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "# 定义数据集的基本路径\n",
    "base_dir = 'D:/dataset'\n",
    "\n",
    "# 数据目录\n",
    "data_directory = base_dir\n",
    "\n",
    "# 批处理大小\n",
    "batch_size = 100\n",
    "\n",
    "# 加载训练数据集\n",
    "train_data = dsets.MNIST(\n",
    "    root=data_directory,  # 数据存储的根目录\n",
    "    train=True,  # 加载训练集\n",
    "    transform=None,  # 不使用任何数据转换\n",
    "    download=True  # 如果数据集不存在则下载\n",
    ")\n",
    "\n",
    "# 加载测试数据集\n",
    "test_data = dsets.MNIST(\n",
    "    root=data_directory,\n",
    "    train=False,  # 加载测试集\n",
    "    transform=None,  # 不使用任何数据转换\n",
    "    download=True  # 如果数据集不存在则下载\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 可视化训练集的一些样本图像和标签\n",
    "num_samples = 10\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    sample_image, sample_label = train_data[i]\n",
    "    plt.imshow(sample_image, cmap='gray')\n",
    "    plt.title(f\"Label: {sample_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 可视化测试集的一些样本图像和标签\n",
    "num_samples = 10\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, num_samples, i + 1)\n",
    "    sample_image, sample_label = test_data[i]\n",
    "    plt.imshow(sample_image, cmap='gray')\n",
    "    plt.title(f\"Label: {sample_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7f5b8-9317-45e0-8f86-dbdacfc1959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classify_knn(k, distance_metric, train_features, train_labels, test_features):\n",
    "    # 确认距离度量参数合法\n",
    "    assert distance_metric in ['E', 'M'], 'distance_metric must be \"E\" for Euclidean or \"M\" for Manhattan'\n",
    "    \n",
    "    # 获取测试样本数量\n",
    "    num_tests = test_features.shape[0]\n",
    "    predicted_labels = []\n",
    "\n",
    "    if distance_metric == 'E':\n",
    "        # 使用欧几里得距离\n",
    "        for i in range(num_tests):\n",
    "            # 计算欧几里得距离\n",
    "            distances = np.sqrt(np.sum((train_features - np.tile(test_features[i], (train_features.shape[0], 1))) ** 2, axis=1))\n",
    "            # 获取最近的k个样本\n",
    "            nearest_neighbors = np.argsort(distances)[:k]\n",
    "            label_counts = {}\n",
    "            for idx in nearest_neighbors:\n",
    "                label_counts[train_labels[idx]] = label_counts.get(train_labels[idx], 0) + 1\n",
    "            # 根据出现频率排序并选择最高频的标签\n",
    "            sorted_labels = sorted(label_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "            predicted_labels.append(sorted_labels[0][0])\n",
    "            \n",
    "            # 可视化当前测试样本与其 k 个最近邻居的图像\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.subplot(1, k + 1, 1)\n",
    "            plt.imshow(test_features[i].reshape(28, 28), cmap='gray')\n",
    "            plt.title(f\"Test Image ({i})\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            for j, idx in enumerate(nearest_neighbors):\n",
    "                plt.subplot(1, k + 1, j + 2)\n",
    "                plt.imshow(train_features[idx].reshape(28, 28), cmap='gray')\n",
    "                plt.title(f\"Nearest Neighbor {j+1}\")\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        # 使用曼哈顿距离\n",
    "        for i in range(num_tests):\n",
    "            # 计算曼哈顿距离\n",
    "            distances = np.sum(np.abs(train_features - np.tile(test_features[i], (train_features.shape[0], 1))), axis=1)\n",
    "            # 获取最近的k个样本\n",
    "            nearest_neighbors = np.argsort(distances)[:k]\n",
    "            label_counts = {}\n",
    "            for idx in nearest_neighbors:\n",
    "                label_counts[train_labels[idx]] = label_counts.get(train_labels[idx], 0) + 1\n",
    "            # 根据出现频率排序并选择最高频的标签\n",
    "            sorted_labels = sorted(label_counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "            predicted_labels.append(sorted_labels[0][0])\n",
    "    \n",
    "    return np.array(predicted_labels)\n",
    "\n",
    "# 输出测试信息\n",
    "print('123')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e88d18-7722-4c6e-b4b1-800e98fbe00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 处理训练数据\n",
    "    train_images = train_loader.dataset.data.numpy()\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28 * 28)\n",
    "    print(\"训练数据形状:\", train_images.shape)\n",
    "    train_labels = train_loader.dataset.targets.numpy()\n",
    "    print(\"训练标签形状:\", train_labels.shape)\n",
    "    \n",
    "    # 处理测试数据\n",
    "    test_images = test_loader.dataset.data[:1000].numpy()\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28 * 28)\n",
    "    print(\"测试数据形状:\", test_images.shape)\n",
    "    test_labels = test_loader.dataset.targets[:1000].numpy()\n",
    "    print(\"测试标签形状:\", test_labels.shape)\n",
    "\n",
    "    # 使用KNN进行分类\n",
    "    predicted_test_labels = classify_knn(5, 'M', train_images, train_labels, test_images)\n",
    "    print('world')\n",
    "    \n",
    "    # 计算准确率\n",
    "    total_tests = test_images.shape[0]\n",
    "    correct_predictions = np.sum(test_labels == predicted_test_labels)\n",
    "    print(\"正确预测数:\", correct_predictions)\n",
    "    accuracy = float(correct_predictions) / total_tests\n",
    "    print('Got %d / %d correct => accuracy: %f' % (correct_predictions, total_tests, accuracy))\n",
    "    \n",
    "    # 可视化一些测试样本的预测结果\n",
    "    num_samples = 10\n",
    "    indices = np.random.choice(len(test_images), num_samples, replace=False)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, num_samples, i + 1)\n",
    "        plt.imshow(test_images[indices[i]].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"True: {test_labels[indices[i]]}, Pred: {predicted_test_labels[indices[i]]}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca1044-af41-44d5-976f-2a1f28f65bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_mean_image(data):\n",
    "    # 重新整形数据为二维数组\n",
    "    reshaped_data = np.reshape(data, (data.shape[0], -1))\n",
    "    # 计算每个像素点的均值\n",
    "    mean_img = np.mean(reshaped_data, axis=0)\n",
    "    return mean_img\n",
    "\n",
    "def mean_centering(data, mean_img):\n",
    "    # 重新整形数据为二维数组\n",
    "    reshaped_data = data.reshape((data.shape[0], -1))\n",
    "    reshaped_data = reshaped_data.astype(np.float64)\n",
    "    # 减去均值实现数据的中心化\n",
    "    centered_data = reshaped_data - mean_img\n",
    "    return centered_data\n",
    "\n",
    "def visualize_predictions(images, true_labels, predicted_labels, title):\n",
    "    num_samples = len(images)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, num_samples, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"True: {true_labels[i]}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, num_samples, i + num_samples + 1)\n",
    "        color = 'green' if true_labels[i] == predicted_labels[i] else 'red'\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"Pred: {predicted_labels[i]}\", color=color)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 处理训练数据\n",
    "    train_images = train_loader.dataset.data.numpy()\n",
    "    mean_img = calculate_mean_image(train_images)  # 计算均值图像\n",
    "    centered_train_images = mean_centering(train_images, mean_img)  # 中心化训练图像\n",
    "    train_labels = train_loader.dataset.targets.numpy()\n",
    "    \n",
    "    # 处理测试数据\n",
    "    test_images = test_loader.dataset.data[:1000].numpy()\n",
    "    centered_test_images = mean_centering(test_images, mean_img)  # 中心化测试图像\n",
    "    test_labels = test_loader.dataset.targets[:1000].numpy()\n",
    "    \n",
    "    # 使用KNN进行分类并进行预测\n",
    "    k = 5\n",
    "    predicted_test_labels = classify_knn(k, 'M', centered_train_images, train_labels, centered_test_images)\n",
    "    \n",
    "    # 计算准确率\n",
    "    accuracy = np.mean(predicted_test_labels == test_labels)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    # 可视化一些测试样本的预测结果\n",
    "    num_samples = 10\n",
    "    indices = np.random.choice(len(test_images), num_samples, replace=False)\n",
    "    visualize_predictions(test_images[indices], test_labels[indices], predicted_test_labels[indices], \"Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a2937-c8de-4c47-812c-6f5a1c301d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed62457-0014-4141-839f-7a6551db0851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
